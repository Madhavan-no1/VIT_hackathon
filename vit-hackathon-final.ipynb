{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9432914,"sourceType":"datasetVersion","datasetId":5731113}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Team Members:\n# Madhavan M\n# Sriram V\n# Siddarth Hilari\n# Auston\n\nimport pandas as pd\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, confusion_matrix, accuracy_score\nimport numpy as np\n\n\n# Load the dataset from CSV\ndf = pd.read_csv('/kaggle/input/datathon/DATATHON_EVENT_DATASET.csv')\n\n# ---- Data Cleaning ----\n# Use ffill directly to forward-fill missing values without a method parameter\ndf.ffill(inplace=True)  # Forward fill missing values\n\n# ---- Label Conversion ----\n# Convert 'Yes'/'No' in 'Fraud' column to 1 and 0\n# This conversion makes the target column numerical, as the model requires numerical input\ndf['Fraud'] = df['Fraud'].map({'Yes': 1, 'No': 0})\n\n# ---- Define Features (X) and Target (y) ----\n# X is the dataset with the 'Fraud' column dropped, as it's the target\n# y is the 'Fraud' column, which we are trying to predict\nX = df.drop(columns=['Fraud'])  # Features (drop the target column)\ny = df['Fraud']  # Target (fraud label)\n\n# ---- Handling High Cardinality Columns ----\n# Label encode columns with high cardinality (i.e., many unique values like Origin_ID and Destination_ID)\n# Label encoding converts these categorical values into numerical labels\nlabel_encoder = LabelEncoder()\nX['Origin_ID'] = label_encoder.fit_transform(X['Origin_ID'])\nX['Destination_ID'] = label_encoder.fit_transform(X['Destination_ID'])\n\n# ---- One-Hot Encoding for Categorical Columns ----\n# One-Hot Encoding is used for categorical columns with few unique values (like 'Transaction_Type', 'Expected_Fraud')\n# This converts categorical data into a binary format (0s and 1s) for model input\ncategorical_cols = ['Transaction_Type', 'Expected_Fraud']\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', OneHotEncoder(drop='first'), categorical_cols)],  # Apply One-Hot Encoding\n    remainder='passthrough'  # Leave other columns (numerical ones) unchanged\n)\n\n# ---- Create the Pipeline ----\n# Pipeline combines preprocessing (encoding + scaling) and model training into one step\n# 1. Preprocessor: Applies one-hot encoding and scaling\n# 2. Scaler: Standardizes numerical features (scaling to make values comparable)\n# 3. Classifier: RandomForestClassifier used for the fraud detection task\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),  # Preprocessing steps (One-Hot Encoding + Pass-through other features)\n    ('scaler', StandardScaler()),  # Standardizes numerical features to have mean 0 and variance 1\n    ('classifier', RandomForestClassifier(random_state=42))  # Random forest model for classification\n])\n\n# ---- Splitting the Data ----\n# Split the data into training and testing sets\n# 80% for training and 20% for testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# ---- Train the Model ----\n# Fit the pipeline to the training data\npipeline.fit(X_train, y_train)\n\n# ---- Predictions and Evaluation ----\n# Make predictions on the test set\ny_pred = pipeline.predict(X_test)\n\n# Calculate F1 Score, Confusion Matrix, and Accuracy\n# F1-Score: Evaluates model performance (balance between precision and recall)\n# Confusion Matrix: Provides insight into true positives, false positives, true negatives, and false negatives\n# Accuracy: Percentage of correct predictions\nf1 = f1_score(y_test, y_pred)\ncm = confusion_matrix(y_test, y_pred)\naccuracy = accuracy_score(y_test, y_pred)\n\n# Print the results to evaluate model performance\nprint(f'Accuracy: {accuracy * 100:.2f}%')  # Accuracy in percentage\nprint(f'F1-Score: {f1}')  # F1 score to measure the balance between precision and recall\nprint('Confusion Matrix:')\nprint(cm)  # Show confusion matrix for evaluation\n\n# ---- Save the Trained Model ----\n# Save the entire pipeline (preprocessing + model) to a file using joblib\n# The saved model can be reloaded for making predictions on new data without retraining\njoblib.dump(pipeline, 'fraud_detection_pipeline.pkl')\nprint(\"Model saved successfully.\")\n\n# The output we got by running this code:\n# Accuracy: 98.91%\n# F1-Score: 0.9604976671850699\n# Confusion Matrix:\n# [[9959   41]   -> (9959 true negatives, 41 false positives)\n#  [  86 1544]]  -> (86 false negatives, 1544 true positives)\n# Model saved successfully.\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T08:56:04.995996Z","iopub.execute_input":"2024-09-19T08:56:04.996389Z","iopub.status.idle":"2024-09-19T08:56:11.588103Z","shell.execute_reply.started":"2024-09-19T08:56:04.996352Z","shell.execute_reply":"2024-09-19T08:56:11.587173Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Accuracy: 98.91%\nF1-Score: 0.9604976671850699\nConfusion Matrix:\n[[9959   41]\n [  86 1544]]\nModel saved successfully.\n","output_type":"stream"}]}]}